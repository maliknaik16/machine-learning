{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb8e64f-b2c3-4ac1-aa17-6789c1cf3ca5",
   "metadata": {},
   "source": [
    "# Basics of PyTorch - Neural Network\n",
    "### Date: 02/20/2025\n",
    "### by Malik N. Mohammed\n",
    "\n",
    "## Objectives\n",
    "- Building Neural networks using PyTorch\n",
    "- Analyze the parameters of the model\n",
    "- Dive into activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ac046a-9cf2-4f22-8ea8-d71fbf2ad22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bad0125-f9d9-4096-9c5e-8612e48adb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f7259b8-106e-4e42-ac1e-d5d739fb45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set print option for truncated output.\n",
    "torch.set_printoptions(precision=2, threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9581c775-99cc-4348-a47b-f242088ea98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the MNIST Dataset\n",
    "data = datasets.MNIST(\n",
    "  'data',\n",
    "  download=True,\n",
    "  transform=transforms.ToTensor() # Convert PIL Image to tensor using torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "189170f7-4607-4f87-afc2-8ff9c7a92fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f0c648c-19ec-4acd-97c8-ac8465b6aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the NeuralNetwork module class.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        # Flatten layer - Converts nd array to 1d\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Linear neural network with ReLU (max(0, x)) activation functions.\n",
    "        # Final layer has 10 nodes which are 10 classes in the dataset.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the dataset before passing through the NN.\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Pass the flatten data and get the logits.\n",
    "        # Logits - raw, unnormalized scores output by the last layer.\n",
    "        # We generally use Softmax function to get the probability distribution over classes.\n",
    "        \n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d7663ac-4087-4952-9ef6-b47f8af81f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model on the accelerator (if available)\n",
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c22a578-a485-4585-a39f-b4506e46638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x75fe70726ba0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dataloader on the MNIST dataset with batch size of 32\n",
    "data_loader = DataLoader(data, batch_size=32, shuffle=True)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18e6d3f7-cfbb-49eb-a393-bc09de1d4520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first batch from the data loader.\n",
    "image, label = next(iter(data_loader))\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28ad59fe-37ce-4cb8-8466-18583d1f1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the image and lable to the accelerator or cpu.\n",
    "X = image.to(device)\n",
    "y = label.to(device)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f7349cc-fe14-45e3-9728-c58c282ffc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0207, -0.0332,  0.0160, -0.0336,  0.0548, -0.0132, -0.0141,  0.0242,\n",
       "          -0.0277, -0.0407]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the 10 logits from the last layer.\n",
    "logits = model(X)\n",
    "\n",
    "logits, logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df9af16d-c461-4a19-b802-e5f1402a173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1025, 0.0971, 0.1020, 0.0971, 0.1061, 0.0991, 0.0990, 0.1029, 0.0977,\n",
       "         0.0964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since our logits are in the dimension 1 we apply softmax on that dimension\n",
    "# and get the probability distribution\n",
    "probability = nn.Softmax(dim=1)(logits)\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9fbca07c-4cee-4ce9-ac87-b8072de4b07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the predicted label we get the index of the maximum probability distribution.\n",
    "probability.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d029894-50ee-4d1b-ad3a-d667312dac2a",
   "metadata": {},
   "source": [
    "## Investigating what happens at each layer.\n",
    "- In this section we explore how each layer is applied without using the NeuralNetwork class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c6046ba-976a-455b-8f34-2f77f94165f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets get the first image and label to use as reference here.\n",
    "image, label = data[0]\n",
    "\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9bf27e2-9a9b-4fff-b662-e3f715b2e20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.]]), torch.Size([1, 784]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We first flatten the image and get it's 1 dimension tensor.\n",
    "x = nn.Flatten()(image)\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f275b542-fd99-4385-bd0b-feabc8c62e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.01,  0.36, -0.43,  ...,  0.03, -0.05,  0.30]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 512]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then pass this value to the first Linear layer.\n",
    "x = nn.Linear(in_features=28*28, out_features=512)(x)\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d17a7ebf-e9ea-49ae-9a69-48085a77ab54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.01, 0.36, 0.00,  ..., 0.03, 0.00, 0.30]], grad_fn=<ReluBackward0>),\n",
       " torch.Size([1, 512]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then pass the output of the first layer to the ReLU activation function (amx(0, x)). So all the values\n",
    "# < 0 are replaced with 0\n",
    "x = nn.ReLU()(x)\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4311fc06-d4f8-462e-9a27-da7f0fe7be9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.08, -0.01,  0.02,  0.03,  0.02,  0.00,  0.06,  0.03,  0.06, -0.04]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We do the same with another Linear layer, followed by ReLU and finally the last layer with 10 nodes.\n",
    "x = nn.Linear(512, 512)(x) # Takes input of 512 size and outputs the same\n",
    "x = nn.ReLU()(x) # Applies ReLU activation on the 512 size tensor.\n",
    "x = nn.Linear(512, 10)(x) # Finally get the tensor of size 10 i.e; 10 classes in the dataset\n",
    "\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba430871-48ba-4a5f-873f-b4dd93fe7e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.09, 0.10, 0.10, 0.10, 0.10, 0.10, 0.11, 0.10, 0.10, 0.10]],\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see that the output of the final layer is not a probability distrbution but a logits. So,\n",
    "# we pass the final layer output through the softmax activation function to get the probabilitic distribution\n",
    "# and pick the index with the maximum probability.\n",
    "x = nn.Softmax(dim=1)(x)\n",
    "x, x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "266f4cba-394c-4664-98c8-8c3bfa38b354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "torch.argmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb53a1a-2520-4b9b-bc78-9661157fb767",
   "metadata": {},
   "source": [
    "### Analyzing model parameters\n",
    "- Each layer of the neural network has parameters called weights and biases.\n",
    "- These weights and biases are optimized during training using backpropagation.\n",
    "- In fully connected (dense) neural network the weights and biases is calculated as follows:\n",
    "  - Weights = Input features * Output Features\n",
    "  - Bias = Output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "73672e99-affb-4655-aa3f-9bf054c3ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight, \t\tWeights Size: torch.Size([512, 784])\n",
      "Layer: linear_relu_stack.0.bias, \t\tBias Size: torch.Size([512])\n",
      "Layer: linear_relu_stack.2.weight, \t\tWeights Size: torch.Size([512, 512])\n",
      "Layer: linear_relu_stack.2.bias, \t\tBias Size: torch.Size([512])\n",
      "Layer: linear_relu_stack.4.weight, \t\tWeights Size: torch.Size([10, 512])\n",
      "Layer: linear_relu_stack.4.bias, \t\tBias Size: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model parameters\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}, \\t\\t{'Weights' if 'weight' in name else 'Bias'} Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c2a7b-071d-4314-bafd-fdc2e7393d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af9eff-67c7-47a0-b91f-33a271d88011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-proprietary",
   "language": "python",
   "name": "llm-proprietary"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
